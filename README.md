# ðŸ«€ 3D Heart Segmentation (UNet + Augmentations)

This repository contains a complete and reproducible pipeline for **3D medical image segmentation** using a **3D U-Net**, including:

- Dataset loading & preprocessing  
- Resampling 
- Geometric & intensity augmentations  
- Sliding-window inference  
- Evaluation (Dice, HD95, Sensitivity, Precision)  
- Visualizations & overlay results  

The code works **locally**, **on Google Colab**, and **inside containers**.

---

## 1. Installation

### **Option A â€” Local Machine**

Clone:
```bash
git clone https://github.com/<your-username>/heart-segmentation.git
cd heart-segmentation
```

Install:
```bash
pip install -r requirements.txt
```

---

### **Option B â€” Google Colab**

```python
!git clone https://github.com/<your-username>/heart-segmentation.git
%cd heart-segmentation
!pip install -r requirements.txt
```

---

## 2. Dataset Structure

```
heart_dataset/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ masks/
â””â”€â”€ test/
    â”œâ”€â”€ images/
    â””â”€â”€ masks/
```

Images are .nii or .nii.gz files.

---

## 3. Environment Variables (optional)

```bash
export DATA_ROOT=/path/to/heart_dataset
export RESULTS_DIR=results
```

---

## 4. Training

Baseline:
```bash
python -m src.train --name baseline
```

Augmented:
```bash
python -m src.train --augment --name augmented
```

---

## 5. Inference & Evaluation

```bash
python -m src.inference
```

Outputs stored in:
```
results/                
â”œâ”€â”€ logs/
â”œâ”€â”€ predictions/
â”œâ”€â”€ augmented_images/
â”œâ”€â”€plots/
â””â”€â”€ checkpoints/
```

---

## 6. Visualizations

Run all visualizations:

```bash
python -m src.visualize
```

Generated files:
```
results/plots/training_curves_baseline.png
results/plots/training_curves_augmented.png
results/augmented_images/aug_examples_train.png
results/predictions/pred_vs_gt_baseline_*.png
results/predictions/pred_vs_gt_augmented_*.png
```

---

## 7. Repository Structure

```
.
â”œâ”€â”€ README.md
â”œâ”€â”€ report
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ io.py          # NIfTI IO, pair matching, resampling
â”‚   â”‚   â”œâ”€â”€ preprocess.py  # normalization, padding, pair preprocessing
â”‚   â”‚   â”œâ”€â”€ patches.py     # patch sampling utilities
â”‚   â”‚   â””â”€â”€ pipelines.py   # tf.data pipelines
â”‚   â”œâ”€â”€ augmentations.py   # geometric + intensity augmentations
â”‚   â”œâ”€â”€ model.py           # 3D U-Net with residual blocks
â”‚   â”œâ”€â”€ losses.py          # Dice, combo loss, LR scheduler
â”‚   â”œâ”€â”€ metrics.py         # HD95, sensitivity, precision
â”‚   â”œâ”€â”€ train.py           # Training entry point (baseline / augmented)
â”‚   â”œâ”€â”€ inference.py       # Sliding-window inference + evaluation
â”‚   â””â”€â”€ plots.py   # plotting utilities 
â”‚   â””â”€â”€ visualize.py       # Generate Original vs Augmented slices + Training curves +  Test predictions
â””â”€â”€ results/               # Created at runtime (metrics, predictions, curves)
    â”œâ”€â”€ logs/
    â”œâ”€â”€ predictions/
    â”œâ”€â”€ augmented_images/
    â”œâ”€â”€ plots/
    â””â”€â”€ checkpoints/

```

---

## 8. Metrics

Metrics CSV:
```
results/baseline_metrics.csv
results/augmented_metrics.csv
```

Columns:
- Dice  
- HD95  
- Sensitivity  
- Precision  

---

## 9. Troubleshooting

**Dataset errors:**
Set correct path in config.py or use:
```bash
export DATA_ROOT=/content/heart_dataset
```

---

## 10. License
MIT License.

---

## 11. Notes
- Fully compatible with local machines and Colab.
- Metrics & visualizations saved in `results/`.

